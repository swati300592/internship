{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711a4d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.12.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from selenium) (0.10.4)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~pencv-python-headless (C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade selenium\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804099f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "# have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "# jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.shine.com/\n",
    "# 2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "# 3. Then click the searchbutton.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce82eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac36a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = r\"C:/Users/ASUS/Downloads/chromedriver_win64/chromedriver.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d78ed618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "chrome_driver_path = r\"C:\\Users\\ASUS\\Downloads\\chromedriver_win64\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "\n",
    "job_title = \"Data Analyst\"\n",
    "location = \"Bangalore\"\n",
    "\n",
    "job_title_input = driver.find_element_by_id(\"autocomplete-skill\")\n",
    "location_input = driver.find_element_by_id(\"autocomplete-location\")\n",
    "search_button = driver.find_element_by_id(\"btnSearch\")\n",
    "\n",
    "job_title_input.send_keys(job_title)\n",
    "location_input.send_keys(location)\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "job_data = []\n",
    "\n",
    "job_cards = driver.find_elements_by_class_name(\"search_listing\")\n",
    "\n",
    "for job_card in job_cards[:10]:\n",
    "    job_title = job_card.find_element_by_class_name(\"job_title\").text\n",
    "    job_location = job_card.find_element_by_class_name(\"job_location\").text\n",
    "    company_name = job_card.find_element_by_class_name(\"comp_name\").text\n",
    "    experience = job_card.find_element_by_class_name(\"exp_in\").text\n",
    "    \n",
    "    job_data.append({\n",
    "        \"Job Title\": job_title,\n",
    "        \"Job Location\": job_location,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Experience Required\": experience\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0c99926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You\n",
    "# have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "# This task will be done in following steps:\n",
    "# 1. First get the webpage https://www.shine.com/\n",
    "# 2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "# 3. Then click the search button.\n",
    "# 4. Then scrape the data for the first 10 jobs results you get.\n",
    "# 5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac129b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "chrome_driver_path = r\"C:\\Users\\ASUS\\Downloads\\chromedriver_win64\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "job_title = \"Data Scientist\"\n",
    "location = \"Bangalore\"\n",
    "\n",
    "job_title_input = driver.find_element_by_name(\"keywords\")\n",
    "location_input = driver.find_element_by_name(\"loc\")\n",
    "\n",
    "job_title_input.send_keys(job_title)\n",
    "location_input.send_keys(location)\n",
    "\n",
    "search_button = driver.find_element_by_id(\"btn\")\n",
    "search_button.click()\n",
    "\n",
    "job_data = []\n",
    "for i in range(10):\n",
    "    try:\n",
    "\n",
    "        job_card = driver.find_elements_by_class_name(\"w-100.job-container\")[i]\n",
    "        job_title = job_card.find_element_by_class_name(\"job-title\").text\n",
    "        job_location = job_card.find_element_by_class_name(\"job-location\").text\n",
    "        company_name = job_card.find_element_by_class_name(\"job-company-name\").text\n",
    "        \n",
    "        job_data.append({\n",
    "            \"Job Title\": job_title,\n",
    "            \"Job Location\": job_location,\n",
    "            \"Company Name\": company_name,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(job_data)\n",
    "\n",
    "print(df)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6a1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
